{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\IPTP\\Stage_3A\\Stage\\Code\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "import os\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from transformers import AutoImageProcessor, AutoModel, AutoProcessor, AutoModelForImageClassification\n",
    "import torch.nn.functional as F\n",
    "from sklearn.random_projection import SparseRandomProjection, GaussianRandomProjection\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, roc_curve\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "SRC_PATH = \"../Data/GenImage/\"\n",
    "generator_names = [\"adm\", \"bgan\", \"glide\", \"midj\", \"sd_14\", \"sd_15\", \"vqdm\", \"wukong\"]\n",
    "with open(\"classes.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "classes_idx = data[\"1k_idx\"]\n",
    "classes_names = data[\"21k_idx\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mad(x, dim=-1, keepdim=False):\n",
    "    \"\"\"\n",
    "    Calculate median absolute deviation (MAD)\n",
    "    MAD = median(|x - median(x)|)\n",
    "    \"\"\"\n",
    "    med = x.median(dim=dim, keepdim=True)[0]\n",
    "    mad = (x - med).abs().median(dim=dim, keepdim=keepdim)[0]\n",
    "\n",
    "    mad = torch.clamp(mad, min=1e-6)\n",
    "    return mad\n",
    "\n",
    "\n",
    "class GaussianRPO:\n",
    "    def __init__(self, D, dtype, M=1000, device=\"cuda\", seed=None):\n",
    "        \"\"\"\n",
    "        D: Data Dimension\n",
    "        M: Number of projectors\n",
    "        \"\"\"\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "        self.device = device\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        # Gaussian random projection M x D\n",
    "        U = torch.randn(M, D, device=device, dtype=dtype)\n",
    "        U = U / U.norm(dim=1, keepdim=True)  # Normalization to sphere of norm 1\n",
    "        self.U = U  # projector matrix\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        Input X: shape (B, D)\n",
    "        Calculation of all MED 和 MAD to cache\n",
    "        \"\"\"\n",
    "        X = X.to(self.device)\n",
    "        # M x B，projection\n",
    "        proj = torch.matmul(self.U, X.T)  # shape (M, B)\n",
    "        self.med = proj.median(dim=1)[0]  # shape (M,)\n",
    "        self.mad = mad(proj, dim=1)  # shape (M,)\n",
    "\n",
    "    def score(self, x):\n",
    "        \"\"\"\n",
    "        Calculation of RPO score for input batch\n",
    "        x: (N, D)\n",
    "        return shape (N,)\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "        # (M, N) = (M, D) @ (D, N)\n",
    "        proj_x = torch.matmul(self.U, x.T)  # shape (M, N)\n",
    "\n",
    "        # broadcast : (M, 1)\n",
    "        med = self.med.unsqueeze(1)\n",
    "        mad = self.mad.unsqueeze(1)\n",
    "\n",
    "        # computation\n",
    "        score = torch.abs(proj_x - med) / mad  # shape (M, N)\n",
    "\n",
    "        # choose the max score as final score for each sample\n",
    "        rpo_score, _ = score.max(dim=0)  # shape (N,)\n",
    "\n",
    "        return rpo_score\n",
    "\n",
    "\n",
    "class SparseRPO:\n",
    "    def __init__(self, D, dtype, M=1000, s=None, device=\"cuda\", seed=None):\n",
    "        \"\"\"\n",
    "        D: original dimension\n",
    "        M: number of projectors\n",
    "        s: parameter of scale of sparsity, by default sqrt(D)\n",
    "        \"\"\"\n",
    "        self.D = D\n",
    "        self.M = M\n",
    "        self.device = device\n",
    "        self.s = s or int(math.sqrt(D))\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        self.U = self._generate_sparse_projection_matrix(dtype)\n",
    "\n",
    "    def _generate_sparse_projection_matrix(self, dtype):\n",
    "        D, M, s = self.D, self.M, self.s\n",
    "        prob_nonzero = 1.0 / s\n",
    "\n",
    "        # initialize all zeros\n",
    "        U = torch.zeros(M, D, device=self.device, dtype=dtype)\n",
    "\n",
    "        # generate uniform random matrix\n",
    "        rand_vals = torch.rand(M, D, device=self.device)\n",
    "\n",
    "        pos_mask = rand_vals < (1 / (2 * s))\n",
    "        neg_mask = (rand_vals >= (1 / (2 * s))) & (rand_vals < (1 / s))\n",
    "\n",
    "        val = math.sqrt(s)\n",
    "        U[pos_mask] = val\n",
    "        U[neg_mask] = -val\n",
    "\n",
    "        # Note: following the implementation of sklearn, there is no normalization\n",
    "\n",
    "        return U\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        calculate MED and MAD for every projection direction\n",
    "        X: (B, D)\n",
    "        \"\"\"\n",
    "        X = X.to(self.device)\n",
    "        proj = torch.matmul(self.U, X.T)  # (M, B)\n",
    "        self.med = proj.median(dim=1)[0]  # (M,)\n",
    "        self.mad = mad(proj, dim=1)  # (M,)\n",
    "\n",
    "    def score(self, x):\n",
    "        \"\"\"\n",
    "        RPO score calculation\n",
    "        x: (N, D)\n",
    "        \"\"\"\n",
    "        x = x.to(self.device)\n",
    "        proj_x = torch.matmul(self.U, x.T)  # (M, N)\n",
    "        med = self.med.unsqueeze(1)  # (M, 1)\n",
    "        mad = self.mad.unsqueeze(1)  # (M, 1)\n",
    "\n",
    "        score = torch.abs(proj_x - med) / mad  # (M, N)\n",
    "        rpo_score, _ = score.max(dim=0)  # (N,)\n",
    "\n",
    "        return rpo_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detector(test_tensor, gt_tensor, labels, M, seed, save_path, device = \"cuda\"):\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    test_tensor = test_tensor.to(device)\n",
    "    gt_tensor = gt_tensor.to(device)\n",
    "    datatype = gt_tensor.dtype\n",
    "    dim = gt_tensor.shape[1]\n",
    "    # rpo = RPO(D=dim, dtype = datatype, M=M, device=device, seed =seed)\n",
    "    rpo = SparseRPO(D=dim, dtype = datatype, M = M, device = device, seed = seed)\n",
    "    rpo.fit(gt_tensor)\n",
    "    scores = rpo.score(test_tensor).cpu()\n",
    "    scores = scores.numpy()\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(labels, scores)\n",
    "    idx = np.where(tpr >= 0.95)[0][0]\n",
    "    fpr_95 = fpr[idx]\n",
    "    distances = np.sqrt((1 - tpr) ** 2 + fpr**2)\n",
    "    best_threshold = thresholds[np.argmin(distances)]\n",
    "    print(\"Best threshold(ROC):\", best_threshold)\n",
    "\n",
    "    roc_auc = roc_auc_score(labels, scores)\n",
    "    # print(\"AUROC:\", roc_auc)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    ax1.plot(fpr, tpr, color=\"darkorange\", lw=2, label=f\"ROC curve (area = {roc_auc:.2f})\")\n",
    "    ax1.plot([0, 1], [0, 1], color=\"navy\", lw=2, linestyle=\"--\")\n",
    "    ax1.set_xlim([0.0, 1.0])\n",
    "    ax1.set_ylim([0.0, 1.05])\n",
    "    ax1.set_xlabel(\"False Positive Rate (FPR)\")\n",
    "    ax1.set_ylabel(\"True Positive Rate (TPR)\")\n",
    "    ax1.set_title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(labels, scores)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    # print(\"AUPRC:\", pr_auc)\n",
    "\n",
    "    ax2.plot(recall, precision, color=\"blue\", lw=2, label=f\"PR curve (area = {pr_auc:.2f})\")\n",
    "    ax2.set_xlim([0.0, 1.0])\n",
    "    ax2.set_ylim([0.0, 1.05])\n",
    "    ax2.set_xlabel(\"Recall\")\n",
    "    ax2.set_ylabel(\"Precision\")\n",
    "    ax2.set_title(\"Precision-Recall Curve\")\n",
    "    ax2.legend(loc=\"best\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path)\n",
    "    plt.close()\n",
    "\n",
    "    return scores, roc_auc, pr_auc, fpr_95\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dinov2Dataset(Dataset):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.image_paths[idx]\n",
    "        try:\n",
    "            image = Image.open(path).convert(\"RGB\")\n",
    "            return image, str(path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failure open image because of {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "def dinov2_collate_fn(batch):\n",
    "    batch = [item for item in batch if item is not None]\n",
    "    if not batch:\n",
    "        return None, None\n",
    "    images, paths = zip(*batch)\n",
    "    return list(images), paths\n",
    "\n",
    "def dinov2_encode(image_paths, batch_size = 64, model_name='facebook/dinov2-with-registers-base', device='cuda'):\n",
    "    processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    image_paths = Path(image_paths)\n",
    "    image_paths = list(image_paths.glob(\"*\"))\n",
    "    dataset = Dinov2Dataset(image_paths)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=dinov2_collate_fn)\n",
    "    embeddings = []\n",
    "\n",
    "    for images, paths in tqdm(dataloader, desc=\"Extracting cls tokens\"):\n",
    "        if images is None:\n",
    "                continue\n",
    "        # processor expects a list of PIL images\n",
    "        inputs = processor(images=images, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            cls_token = outputs.last_hidden_state[:, 0, :]  # remove CLS\n",
    "            embeddings.append(cls_token.detach().cpu())\n",
    "\n",
    "    embedding_all = torch.cat(embeddings, dim=0)\n",
    "    \n",
    "    return embedding_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting cls tokens: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:08<00:00,  2.79s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.56s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.13s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.65s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.02s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.08s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.31s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.05s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.08s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.62s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:08<00:00,  2.81s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.08s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.58s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.33s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:09<00:00,  3.09s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:04<00:00,  1.59s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]\n",
      "Extracting cls tokens: 100%|██████████| 3/3 [00:03<00:00,  1.26s/it]\n"
     ]
    }
   ],
   "source": [
    "for cls in classes_idx:\n",
    "    for generator in [\"bgan\", \"midj\", \"sd_15\", \"nature\", \"nature_2\"]:\n",
    "        cls_tokens = dinov2_encode(f\"../Data/GenImage/{cls}/{generator}\")\n",
    "        save_path = f\"../Data/Features/dinov2cls/{cls}/{generator}.pt\"\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        torch.save(cls_tokens, save_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold(ROC): 6.0072775\n",
      "Best threshold(ROC): 5.009192\n",
      "Best threshold(ROC): 5.340401\n",
      "Best threshold(ROC): 5.97304\n",
      "Best threshold(ROC): 5.496476\n",
      "Best threshold(ROC): 3.9286146\n",
      "Best threshold(ROC): 6.998828\n",
      "Best threshold(ROC): 4.7329526\n",
      "Best threshold(ROC): 4.4633145\n",
      "Best threshold(ROC): 5.0392346\n",
      "Best threshold(ROC): 5.189156\n",
      "Best threshold(ROC): 4.7727094\n",
      "Best threshold(ROC): 5.613031\n",
      "Best threshold(ROC): 3.730882\n",
      "Best threshold(ROC): 4.224724\n",
      "Best threshold(ROC): 5.3669615\n",
      "Best threshold(ROC): 4.2515326\n",
      "Best threshold(ROC): 5.650461\n",
      "Best threshold(ROC): 6.17908\n",
      "Best threshold(ROC): 5.7054234\n",
      "Best threshold(ROC): 6.1334214\n",
      "Best threshold(ROC): 7.3345876\n",
      "Best threshold(ROC): 6.2571163\n",
      "Best threshold(ROC): 6.298293\n",
      "Best threshold(ROC): 5.52156\n",
      "Best threshold(ROC): 6.9023576\n",
      "Best threshold(ROC): 6.9989862\n",
      "Best threshold(ROC): 5.5880017\n",
      "Best threshold(ROC): 5.0488777\n",
      "Best threshold(ROC): 6.041898\n",
      "dinov2cls auroc: 0.6201760402377686, auprc: 0.6058481069587169, fpr95: 0.7045267489711935\n"
     ]
    }
   ],
   "source": [
    "auroc = []\n",
    "auprc = []\n",
    "fpr95 = []\n",
    "generator = []\n",
    "for cls in classes_idx:\n",
    "    bgan = torch.load(f\"../Data/Features/dinov2cls/{cls}/bgan.pt\", weights_only=True)\n",
    "    midj = torch.load(f\"../Data/Features/dinov2cls/{cls}/midj.pt\", weights_only=True)\n",
    "    sd_15 = torch.load(f\"../Data/Features/dinov2cls/{cls}/sd_15.pt\", weights_only=True)\n",
    "    nature = torch.load(f\"../Data/Features/dinov2cls/{cls}/nature.pt\", weights_only=True)\n",
    "    nature_2 = torch.load(f\"../Data/Features/dinov2cls/{cls}/nature_2.pt\", weights_only=True)\n",
    "    bgan_m = torch.cat([nature_2, bgan], dim=0).to(device)\n",
    "    midj_m = torch.cat([nature_2, midj], dim=0).to(device)\n",
    "    sd_15_m = torch.cat([nature_2, sd_15], dim=0).to(device)\n",
    "    labels = np.concatenate((np.zeros(nature_2.shape[0]), np.ones(bgan.shape[0])))\n",
    "    s1, r1, p1, f1 = detector(\n",
    "        bgan_m,\n",
    "        nature,\n",
    "        labels,\n",
    "        1000,\n",
    "        2025,\n",
    "        f\"../Data/RPO/Sparse/dinov2cls/{cls}/bgan.png\",\n",
    "    )\n",
    "    generator.append(\"bgan\")\n",
    "    auroc.append(r1)\n",
    "    auprc.append(p1)\n",
    "    fpr95.append(f1)\n",
    "    s2, r2, p2, f2 = detector(\n",
    "        midj_m,\n",
    "        nature,\n",
    "        labels,\n",
    "        1000,\n",
    "        2025,\n",
    "        f\"../Data/RPO/Sparse/dinov2cls/{cls}/midj.png\",\n",
    "    )\n",
    "    generator.append(\"midj\")\n",
    "    auroc.append(r2)\n",
    "    auprc.append(p2)\n",
    "    fpr95.append(f2)\n",
    "    s3, r3, p3, f3 = detector(\n",
    "        sd_15_m,\n",
    "        nature,\n",
    "        labels,\n",
    "        1000,\n",
    "        2025,\n",
    "        f\"../Data/RPO/Sparse/dinov2cls/{cls}/sd_15.png\",\n",
    "    )\n",
    "    generator.append(\"sd_15\")\n",
    "    auroc.append(r3)\n",
    "    auprc.append(p3)\n",
    "    fpr95.append(f3)\n",
    "data = {\n",
    "    \"CLASS\": [x for x in classes_idx for _ in range(3)],\n",
    "    \"GENERATOR\": generator,\n",
    "    \"AUROC\": auroc,\n",
    "    \"AUPRC\": auprc,\n",
    "    \"FPR95\": fpr95,\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(\"dinov2cls_rpo2_result.csv\", index=False)\n",
    "print(f\"dinov2cls auroc: {np.mean(auroc)}, auprc: {np.mean(auprc)}, fpr95: {np.mean(fpr95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold(ROC): -5.47\n",
      "Best threshold(ROC): -5.684\n",
      "Best threshold(ROC): -4.73\n",
      "Best threshold(ROC): -5.004\n",
      "Best threshold(ROC): -5.152\n",
      "Best threshold(ROC): -4.887\n",
      "Best threshold(ROC): -5.055\n",
      "Best threshold(ROC): -5.258\n",
      "Best threshold(ROC): -4.465\n",
      "Best threshold(ROC): -4.8\n",
      "Best threshold(ROC): -5.84\n",
      "Best threshold(ROC): -4.8\n",
      "Best threshold(ROC): -5.137\n",
      "Best threshold(ROC): -5.06\n",
      "Best threshold(ROC): -4.707\n",
      "Best threshold(ROC): -4.945\n",
      "Best threshold(ROC): -4.82\n",
      "Best threshold(ROC): -4.945\n",
      "Best threshold(ROC): -5.812\n",
      "Best threshold(ROC): -5.445\n",
      "Best threshold(ROC): -4.223\n",
      "Best threshold(ROC): -5.543\n",
      "Best threshold(ROC): -5.68\n",
      "Best threshold(ROC): -5.344\n",
      "Best threshold(ROC): -5.344\n",
      "Best threshold(ROC): -5.65\n",
      "Best threshold(ROC): -5.65\n",
      "Best threshold(ROC): -5.14\n",
      "Best threshold(ROC): -4.76\n",
      "Best threshold(ROC): -4.38\n",
      "clip auroc: 0.5177729512777524, auprc: 0.5676631833058587, fpr95: 0.9370370370370369\n",
      "Best threshold(ROC): -5.9389734\n",
      "Best threshold(ROC): -5.422695\n",
      "Best threshold(ROC): -5.14986\n",
      "Best threshold(ROC): -5.778146\n",
      "Best threshold(ROC): -4.788197\n",
      "Best threshold(ROC): -4.329754\n",
      "Best threshold(ROC): -6.1955047\n",
      "Best threshold(ROC): -5.8040533\n",
      "Best threshold(ROC): -5.0964217\n",
      "Best threshold(ROC): -5.5767436\n",
      "Best threshold(ROC): -5.4961414\n",
      "Best threshold(ROC): -5.2643723\n",
      "Best threshold(ROC): -5.7202935\n",
      "Best threshold(ROC): -4.825643\n",
      "Best threshold(ROC): -5.122163\n",
      "Best threshold(ROC): -5.7492213\n",
      "Best threshold(ROC): -4.5537305\n",
      "Best threshold(ROC): -5.1576624\n",
      "Best threshold(ROC): -5.0567255\n",
      "Best threshold(ROC): -5.884638\n",
      "Best threshold(ROC): -5.0206504\n",
      "Best threshold(ROC): -6.254164\n",
      "Best threshold(ROC): -5.6749434\n",
      "Best threshold(ROC): -5.6749434\n",
      "Best threshold(ROC): -5.5127687\n",
      "Best threshold(ROC): -6.02451\n",
      "Best threshold(ROC): -6.02451\n",
      "Best threshold(ROC): -5.2743683\n",
      "Best threshold(ROC): -5.1360188\n",
      "Best threshold(ROC): -4.5571976\n",
      "dinov2 auroc: 0.6249847584209722, auprc: 0.6580157905309094, fpr95: 0.8524691358024691\n",
      "Best threshold(ROC): -3.867477\n",
      "Best threshold(ROC): -3.867477\n",
      "Best threshold(ROC): -4.953997\n",
      "Best threshold(ROC): -3.0550692\n",
      "Best threshold(ROC): -4.0959706\n",
      "Best threshold(ROC): -7.4410133\n",
      "Best threshold(ROC): -3.7408333\n",
      "Best threshold(ROC): -4.30848\n",
      "Best threshold(ROC): -4.437087\n",
      "Best threshold(ROC): -2.5170069\n",
      "Best threshold(ROC): -3.8464656\n",
      "Best threshold(ROC): -4.5532393\n",
      "Best threshold(ROC): inf\n",
      "Best threshold(ROC): -4.7779107\n",
      "Best threshold(ROC): -7.4131804\n",
      "Best threshold(ROC): -2.795213\n",
      "Best threshold(ROC): -4.1487293\n",
      "Best threshold(ROC): -4.888753\n",
      "Best threshold(ROC): -3.4407585\n",
      "Best threshold(ROC): -4.8294787\n",
      "Best threshold(ROC): -4.4029145\n",
      "Best threshold(ROC): -3.910013\n",
      "Best threshold(ROC): -4.536258\n",
      "Best threshold(ROC): -5.3699036\n",
      "Best threshold(ROC): -3.335561\n",
      "Best threshold(ROC): -3.760378\n",
      "Best threshold(ROC): -4.2122436\n",
      "Best threshold(ROC): -3.4484751\n",
      "Best threshold(ROC): -3.8721159\n",
      "Best threshold(ROC): -4.4780803\n",
      "wst auroc: 0.45716227201138043, auprc: 0.5148643530686755, fpr95: 0.925514403292181\n"
     ]
    }
   ],
   "source": [
    "for embedder in [\"clip\", \"dinov2\", \"wst\"]:\n",
    "        auroc = []\n",
    "        auprc = []\n",
    "        fpr95 = []\n",
    "        generator = []\n",
    "        for cls in classes_idx:\n",
    "            bgan = torch.load(f\"../Data/Features/{embedder}/{cls}/bgan.pt\", weights_only=True)[\"features\"]\n",
    "            midj = torch.load(f\"../Data/Features/{embedder}/{cls}/midj.pt\", weights_only=True)[\"features\"]\n",
    "            sd_15 = torch.load(f\"../Data/Features/{embedder}/{cls}/sd_15.pt\", weights_only=True)[\"features\"]\n",
    "            nature = torch.load(f\"../Data/Features/{embedder}/{cls}/nature.pt\", weights_only=True)[\"features\"]\n",
    "            nature_2 = torch.load(f\"../Data/Features/{embedder}/{cls}/nature_2.pt\", weights_only=True)[\"features\"]\n",
    "            bgan_m = torch.cat([bgan, nature_2], dim=0).to(device)\n",
    "            midj_m = torch.cat([midj, nature_2], dim=0).to(device)\n",
    "            sd_15_m = torch.cat([sd_15, nature_2], dim=0).to(device)\n",
    "            labels = np.concatenate((np.zeros(bgan.shape[0]), np.ones(nature_2.shape[0])))\n",
    "            s1, r1, p1, f1 = detector(\n",
    "                bgan_m,\n",
    "                nature,\n",
    "                labels,\n",
    "                1000,\n",
    "                2025,\n",
    "                f\"../Data/RPO/Sparse/{embedder}/{cls}/bgan.png\",\n",
    "            )\n",
    "            generator.append(\"bgan\")\n",
    "            auroc.append(r1)\n",
    "            auprc.append(p1)\n",
    "            fpr95.append(f1)\n",
    "            s2, r2, p2, f2 = detector(\n",
    "                midj_m,\n",
    "                nature,\n",
    "                labels,\n",
    "                1000,\n",
    "                2025,\n",
    "                f\"../Data/RPO/Sparse/{embedder}/{cls}/midj.png\",\n",
    "            )\n",
    "            generator.append(\"midj\")\n",
    "            auroc.append(r2)\n",
    "            auprc.append(p2)\n",
    "            fpr95.append(f2)\n",
    "            s3, r3, p3, f3 = detector(\n",
    "                sd_15_m,\n",
    "                nature,\n",
    "                labels,\n",
    "                1000,\n",
    "                2025,\n",
    "                f\"../Data/RPO/Sparse/{embedder}/{cls}/sd_15.png\",\n",
    "            )\n",
    "            generator.append(\"sd_15\")\n",
    "            auroc.append(r3)\n",
    "            auprc.append(p3)\n",
    "            fpr95.append(f3)\n",
    "        data = {\n",
    "            \"CLASS\": [x for x in classes_idx for _ in range(3)],\n",
    "            \"GENERATOR\": generator,\n",
    "            \"AUROC\": auroc,\n",
    "            \"AUPRC\": auprc,\n",
    "            \"FPR95\": fpr95,\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        df.to_csv(embedder + \"_rpo2_result.csv\", index=False)\n",
    "        print(embedder + f\" auroc: {np.mean(auroc)}, auprc: {np.mean(auprc)}, fpr95: {np.mean(fpr95)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
